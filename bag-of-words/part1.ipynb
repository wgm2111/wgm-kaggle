{
 "metadata": {
  "name": "part1"
 }, 
 "nbformat": 2, 
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown", 
     "source": [
      "# Tutorial on the Bag of Words model", 
      "This tutorial involves the prediction of movie ratings based on the text review that goes along with the raiting.  ", 
      "Data came from the IMDB and can be downloaded from kaggle: http://www.kaggle.com/.", 
      "", 
      "", 
      "##So lets load the data and have a look . . . "
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "import pandas as pd", 
      "train = pd.read_csv(\"labeledTrainData.tsv\", ", 
      "                    header=0, delimiter=\"\\t\", quoting=3)", 
      "print(\"Training set shape: \\t\\t{}\".format(train.shape))", 
      "print((\"Column names data frame: \\t{}, {}, {}.\\n\"", 
      "       ).format(*train.columns.values))", 
      "print(train[:10])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "Training set shape: \t\t(25000, 3)", 
        "Column names data frame: \tid, sentiment, review.", 
        "", 
        "          id  sentiment                                             review", 
        "0   \"5814_8\"          1  \"With all this stuff going down at the moment ...", 
        "1   \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...", 
        "2   \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...", 
        "3   \"3630_4\"          0  \"It must be assumed that those who praised thi...", 
        "4   \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...", 
        "5   \"8196_8\"          1  \"I dont know why people think this is such a b...", 
        "6   \"7166_2\"          0  \"This movie could have been very good, but com...", 
        "7  \"10633_1\"          0  \"I watched this video at a friend's house. I'm...", 
        "8    \"319_1\"          0  \"A friend of mine bought this film for \u00a31, and...", 
        "9  \"8713_10\"          1  \"<br /><br />This movie is full of references...."
       ]
      }
     ], 
     "prompt_number": 128
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "##The HTML tags are not wanted so lets import bs4.BeautifulSoup and \"get_text()\":"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "from bs4 import BeautifulSoup     # An appropriately named package"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 106
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "example1 = BeautifulSoup(train['review'][0])", 
      "print(\"\\n\\nMarked up HTML: \\n{0} . . .\".format(str(example1)[:80]))", 
      "print(\"\\n\\nClean text:\\n{} . . . \".format(example1.get_text()[:80]))"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "", 
        "", 
        "Marked up HTML: ", 
        "<html><body><p>\"With all this stuff going down at the moment with MJ i've starte . . .", 
        "", 
        "", 
        "Clean text:", 
        "\"With all this stuff going down at the moment with MJ i've started listening to  . . . "
       ]
      }
     ], 
     "prompt_number": 139
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "##Strip off punctuation"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "import re", 
      "", 
      "# Find characters that are not lower or uppercase letters", 
      "letters_only = re.sub(\"[^a-zA-Z]\", \" \", example1.get_text())", 
      "print(\"Text with Letters only: \\n{} . . . \\n\".format(letters_only[:80]))", 
      "", 
      "# Now we \"tokenize\" (convert to lowercase and split into a list of words)", 
      "words = letters_only.lower().split()", 
      "msg = \"List of lowercase words, with the first 5 as follows: \\n{}\\n\"", 
      "print(msg.format(words[:5]))"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "Text with Letters only: ", 
        " With all this stuff going down at the moment with MJ i ve started listening to  . . . ", 
        "", 
        "List of lowercase words, with the first 5 as follows: ", 
        "[u'with', u'all', u'this', u'stuff', u'going']", 
        ""
       ]
      }
     ], 
     "prompt_number": 144
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## The next step is to remove \"stop words,\" such as \"the\", \"a\", and \"is\". "
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# Powerful toolkit with a large corpus ", 
      "from nltk.corpus import stopwords", 
      "msg = 'The english stop words are as follows:\\n\\n{}\\n'", 
      "print(msg.format(stopwords.words('english')))", 
      "", 
      "#removing stop words by checking if they are in the set", 
      "stopword_set = set(stopwords.words('english'))", 
      "words = [w for w in words if not (w in stopword_set)]"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "The english stop words are as follows:", 
        "", 
        "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now']", 
        ""
       ]
      }
     ], 
     "prompt_number": 145
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Encapsulate the above process in a function"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from bs4 import BeautifulSoup", 
      "import re", 
      "from nltk.corpus import stopwords", 
      "", 
      "# define the stop set for checking", 
      "stop_set = set(stopwords.words(\"english\"))", 
      "", 
      "# Function for cleaning the reviews", 
      "def review_to_words(raw_review, stop_set=stop_set):", 
      "    \"Take a raw review in English and return the tokenized and 'useful' words.\"", 
      "    # Strip HTML tags", 
      "    review_text = BeautifulSoup(raw_review).get_text()", 
      "", 
      "    # Strip non-letter characters", 
      "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text).lower()", 
      "", 
      "    # Split good words into a list", 
      "    words = [w for w in letters_only.split() if not (w in stop_set)]", 
      "    return words", 
      "", 
      "# Quick test", 
      "print(\" \".join(review_to_words(\"The big fat bear has hair\")))"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "big fat bear hair"
       ]
      }
     ], 
     "prompt_number": 149
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "clean_review = review_to_words(train['review'][0])", 
      "print(\"Raw:\\t\" + train['review'][0][1:80])", 
      "print(\"Clean:\\t\" + \" \".join(clean_review[:10]))"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "Raw:\tWith all this stuff going down at the moment with MJ i've started listening to ", 
        "Clean:\tstuff going moment mj ve started listening music watching odd"
       ]
      }
     ], 
     "prompt_number": 158
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Go through the DataFrame and make an extra column for the processed words"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "words = []", 
      "for review in train['review'].values:", 
      "    words.append(\" \".join(review_to_words(review)))", 
      "    ", 
      "# store words in a new column", 
      "train['words'] = words"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 159
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "print(train[:10])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "          id  sentiment                                             review  \\", 
        "0   \"5814_8\"          1  \"With all this stuff going down at the moment ...   ", 
        "1   \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...   ", 
        "2   \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...   ", 
        "3   \"3630_4\"          0  \"It must be assumed that those who praised thi...   ", 
        "4   \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...   ", 
        "5   \"8196_8\"          1  \"I dont know why people think this is such a b...   ", 
        "6   \"7166_2\"          0  \"This movie could have been very good, but com...   ", 
        "7  \"10633_1\"          0  \"I watched this video at a friend's house. I'm...   ", 
        "8    \"319_1\"          0  \"A friend of mine bought this film for \u00a31, and...   ", 
        "9  \"8713_10\"          1  \"<br /><br />This movie is full of references....   ", 
        "", 
        "                                               words  ", 
        "0  stuff going moment mj ve started listening mus...  ", 
        "1  classic war worlds timothy hines entertaining ...  ", 
        "2  film starts manager nicholas bell giving welco...  ", 
        "3  must assumed praised film greatest filmed oper...  ", 
        "4  superbly trashy wondrously unpretentious explo...  ", 
        "5  dont know people think bad movie got pretty go...  ", 
        "6  movie could good comes way short cheesy specia...  ", 
        "7  watched video friend house m glad waste money ...  ", 
        "8  friend mine bought film even grossly overprice...  ", 
        "9  movie full references like mad max ii wild one...  "
       ]
      }
     ], 
     "prompt_number": 160
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "##Vectorize using tools in sklearn"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer", 
      "", 
      "vectorizer = CountVectorizer(analyzer=\"word\", ", 
      "                             tokenizer=None, ", 
      "                             preprocessor=None, ", 
      "                             stop_words=None, ", 
      "                             max_features=5000)", 
      "", 
      "# fit transform to get features", 
      "train_data_features = vectorizer.fit_transform(train['words'])", 
      "", 
      "# Define the training features as an array", 
      "Xtrain = train_data_features.toarray()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 161
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "Xtrain.shape"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "pyout", 
       "prompt_number": 162, 
       "text": [
        "(25000, 5000)"
       ]
      }
     ], 
     "prompt_number": 162
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "vocab = vectorizer.get_feature_names()", 
      "print(vocab[:10])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "[u'abandoned', u'abc', u'abilities', u'ability', u'able', u'abrupt', u'absence', u'absent', u'absolute', u'absolutely']"
       ]
      }
     ], 
     "prompt_number": 163
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "vocab_table = pd.DataFrame({'word' : vocab, ", 
      "                            'count' : Xtrain.sum(0)})", 
      "msg = \"The Word counts of the top 50 words are as follows:\"", 
      "print(msg)", 
      "print(vocab_table.sort('count', ascending=False)[:5])"
     ], 
     "language": "python", 
     "outputs": [
      {
       "output_type": "stream", 
       "stream": "stdout", 
       "text": [
        "The Word counts of the top 50 words are as follows:", 
        "      count        word", 
        "2896  44030       movie", 
        "1690  40146        film", 
        "3074  26788         one", 
        "2570  20274        like", 
        "1910  15140        good", 
        "4507  12723        time", 
        "1496  12646        even", 
        "4961  12436       would", 
        "4221  11983       story", 
        "3537  11736      really", 
        "3863  11474         see", 
        "4865  10661        well", 
        "2904   9765        much", 
        "1874   9310         get", 
        "332    9301         bad", 
        "3189   9285      people", 
        "148    9155        also", 
        "1713   9061       first", 
        "1939   9058       great", 
        "2672   8362        made", 
        "4842   8026         way", 
        "2688   8021        make", 
        "968    7921       could", 
        "2897   7663      movies", 
        "4465   7296       think", 
        "700    7154  characters", 
        "698    7022   character", 
        "4833   6972       watch", 
        "4632   6906         two", 
        "1695   6887       films", 
        "3872   6679        seen", 
        "2706   6675        many", 
        "2562   6628        life", 
        "3278   6585        plot", 
        "44     6490      acting", 
        "2972   6484       never", 
        "2643   6453        love", 
        "2596   6435      little", 
        "414    6414        best", 
        "3969   6294        show", 
        "2460   6166        know", 
        "1501   5995        ever", 
        "2695   5982         man", 
        "417    5737      better", 
        "1429   5648         end", 
        "4204   5622       still", 
        "3809   5395         say", 
        "3818   5378       scene", 
        "3820   5207      scenes", 
        "4733   5182          ve"
       ]
      }
     ], 
     "prompt_number": 164
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "## Now lets get to some machine learning classify sentiment based on the text review"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "from sklearn.ensemble import RandomForestClassifier", 
      "", 
      "# The training data", 
      "ytrain = train['sentiment']", 
      "", 
      "# initialize the forest with 100 trees", 
      "forest = RandomForestClassifier(n_estimators=100)", 
      "", 
      "# Fit the forest to the training set", 
      "forest = forest.fit(Xtrain, ytrain)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": "*"
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "##Creating a submission"
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "#reading test data", 
      "test = pd.read_csv('testData.tsv', header=0, delimiter=\"\\t\", quoting=3)", 
      "print(test.shape) # quick check on the shape of data"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": "*"
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# Creat a list of clean reviews", 
      "clean_test_reviews = []", 
      "Nreviews = len(test)", 
      "for i, review in enumerate(test['review']):", 
      "    if (i+1) % 1000 ==0: ", 
      "        print(\"Review {0:6d}  of  {1:10d}\".format(i, Nreviews))", 
      "    #Make a clean review and append to the list", 
      "    clean_review = review_to_words(review)", 
      "    clean_test_reviews.append(\" \".join(clean_review))"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": "*"
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "# Vectorize the clean word lists", 
      "test_features = vectorizer.transform(clean_test_reviews)", 
      "Xtest = test_features.toarray()"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": "*"
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [
      "ypredict = forest.predict(Xtest)", 
      "ypredict_frame = pd.DataFrame(data = {'id': test['id'], ", 
      "                                      'sentiment': ypredict,", 
      "                                      'words':clean_test_reviews}) "
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": "*"
    }, 
    {
     "cell_type": "code", 
     "collapsed": false, 
     "input": [
      "print(ypredict_frame[:50])", 
      "ypredict_frame.to_csv('test_output_with_words.csv')", 
      "ypredict_frame.ix[:,['id', 'sentiment']].to_csv(\"Bag_of_Words_model.csv\", index=False, quoting=3)"
     ], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": "*"
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": [], 
     "prompt_number": 124
    }, 
    {
     "cell_type": "markdown", 
     "source": [
      "# Submission results: I recieved a score of .84468 which is about average for the Bag of Words method used in the tutorial.  Since I didn't try anything special that makes sense.  The best score was .97959."
     ]
    }, 
    {
     "cell_type": "code", 
     "collapsed": true, 
     "input": [], 
     "language": "python", 
     "outputs": []
    }
   ]
  }
 ]
}